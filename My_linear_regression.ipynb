{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneSll/ML_Algorithms/blob/main/My_linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZFoTqiyMhZd5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "data = load_diabetes(as_frame=True)\n",
        "X, y = data['data'], data['target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "9WIwRlemniqv"
      },
      "outputs": [],
      "source": [
        "class MyLineReg:\n",
        "\n",
        "  def __init__(self, n_iter=100, learning_rate=0.1, metric=None):\n",
        "    self.n_iter = n_iter\n",
        "    self.learning_rate = learning_rate\n",
        "    self.weights = None\n",
        "    self.metric = metric\n",
        "    self.best_score = None\n",
        "\n",
        "\n",
        "  def __str__(self):\n",
        "    oup_string = \"MyLineReg class: \"\n",
        "    d = vars(self)\n",
        "    for key, val in d.items():\n",
        "      oup_string += str(key) + \"=\" + str(val) + \", \"\n",
        "\n",
        "    return oup_string\n",
        "\n",
        "  def get_best_score(self):\n",
        "      return self.best_score\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def _mse_loss(y, y_pred):\n",
        "        return np.mean((y_pred.T - y) ** 2)\n",
        "\n",
        "\n",
        "  def _get_metric(self, y, y_hat):\n",
        "    if (self.metric == \"mae\"):\n",
        "      return np.mean(np.fabs(y_hat.T - y))\n",
        "    elif (self.metric == \"mse\"):\n",
        "      return np.mean((y_hat.T - y) ** 2)\n",
        "    elif (self.metric == \"rmse\"):\n",
        "      return (np.mean((y_hat.T - y) ** 2))**(1/2)\n",
        "    elif (self.metric == \"mape\"):\n",
        "      return (np.mean(np.fabs((y_hat.T - y)/ y)) * 100)\n",
        "    elif (self.metric == \"r2\"):\n",
        "      return (1 - (((y_hat.T - y) ** 2).sum() /((y - y.mean()) ** 2).sum()).iloc[0])\n",
        "\n",
        "\n",
        "  def fit(self, X, y, verbose=False):\n",
        "    y = y.to_numpy().reshape(-1, 1)\n",
        "    new_X = X.copy()\n",
        "    new_X.insert(0, \"x_0\", [1 for i in range(len(X))]) # add additional column consists of all 1 for x_0\n",
        "    self.weights = np.ones((1, X.shape[1] + 1)) #vector of weights inited by 1\n",
        "    for i in range(self.n_iter):\n",
        "      y_hat = self.weights @ new_X.T\n",
        "      loss = self._mse_loss(y, y_hat)\n",
        "      grad = (2 / len(y)) * np.dot(new_X.T, (y_hat.T - y))\n",
        "      self.weights -= self.learning_rate * grad.T\n",
        "      if (verbose and ((i % verbose) == 0) and self.metric is None):\n",
        "        if (i == 0):\n",
        "          print(f\"start|loss: {loss}\")\n",
        "        else:\n",
        "          print(f\"{i}|loss:{loss}\")\n",
        "      elif (verbose and ((i % verbose) == 0) and self.metric is not(None)):\n",
        "        if (i == 0):\n",
        "          print(f\"start|loss: {loss}|{self.metric}:{self._get_metric(y, y_hat)}\")\n",
        "        else:\n",
        "          print(f\"{i}|loss:{loss}|{self.metric}:{self._get_metric(y, y_hat)}\")\n",
        "\n",
        "    if self.metric is not(None):\n",
        "      self.best_score = self._get_metric(y, y_hat)\n",
        "\n",
        "\n",
        "  def get_coef(self):\n",
        "    return np.mean(self.weights.reshape(-1,1)[1:])\n",
        "\n",
        "  def predict(self, X):\n",
        "    new_X = X.copy()\n",
        "    new_X.insert(0, \"x_0\", [1 for i in range(len(X))]) # add additional column consists of all 1 for x_0\n",
        "    y_hat = np.dot(new_X, self.weights.T)\n",
        "    return y_hat.sum()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = MyLineReg(50, 0.1, metric = \"mae\")"
      ],
      "metadata": {
        "id": "_HdOt0GLwzh_"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ti5mg7R2i5YO"
      },
      "outputs": [],
      "source": [
        "test.fit(X, y, verbose = 10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.get_best_score()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niD4ZCoE-OnZ",
        "outputId": "d03952fe-2443-4001-d60e-9a94a36fe747"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.05234897834990915"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = make_regression(n_samples=400, n_informative=5, noise=5)\n",
        "X = pd.DataFrame(X)\n",
        "y = pd.Series(y)"
      ],
      "metadata": {
        "id": "gJvrgxO2KWWK"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test2 = MyLineReg(50, 0.1, \"mae\")"
      ],
      "metadata": {
        "id": "Lu4vIp13K31m"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test2.fit(X, y, verbose = 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pPxCArdK7j2",
        "outputId": "20a70bc6-24d7-449e-9ae8-00bcb38ff207"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start|loss: 33683.54291951528|mae:144.64879493950062\n",
            "10|loss:711.6438605442331|mae:21.372086633580047\n",
            "20|loss:102.68128026627714|mae:8.06150675962899\n",
            "30|loss:32.6365936814222|mae:4.4940711275948\n",
            "40|loss:21.238048109578987|mae:3.6052381699072247\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test2.predict(X)"
      ],
      "metadata": {
        "id": "yz6p19Y7N9vq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnfuISJCxlJuUAgjIoxT+X",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}